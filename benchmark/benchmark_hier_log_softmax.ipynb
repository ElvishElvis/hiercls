{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf226190",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18ee382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# TODO: pip install -e hier\n",
    "PROJECT_ROOT = pathlib.Path('.').absolute().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0881173",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCE_DIR = pathlib.Path('../resources')\n",
    "with open(RESOURCE_DIR / 'hierarchy/imagenet_fiveai.csv') as f:\n",
    "    edges = hier.load_edges(f)\n",
    "tree, names = hier.make_hierarchy_from_edges(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f10347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1372)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.num_leaf_nodes(), tree.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0667f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1024\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5767d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = tree.num_nodes()\n",
    "num_edges = tree.num_nodes() - 1\n",
    "num_internal = tree.num_internal_nodes()\n",
    "num_leaf = tree.num_leaf_nodes()\n",
    "max_children = max(map(len, tree.children().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165e972c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70d452e0>\n",
       "torch.log_softmax(theta, dim=-1)\n",
       "  20.73 us\n",
       "  1 measurement, 10000 runs , 1 thread"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark a vanilla softmax function, for reference.\n",
    "\n",
    "theta = torch.randn([b, num_edges]).to(device)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='torch.log_softmax(theta, dim=-1)',\n",
    "    globals={'theta': theta})\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986cab0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70d454c0>\n",
       "cat_log_softmax_split(theta, dim=-1)\n",
       "  2.81 ms\n",
       "  1 measurement, 100 runs , 1 thread"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark cat . log_softmax . split.\n",
    "# This is the minimum required for softmaxes of different sizes.\n",
    "\n",
    "node_to_children = tree.children()\n",
    "cond_children = [node_to_children[x] for x in tree.internal_subset()]\n",
    "cond_sizes = [len(x) for x in cond_children]\n",
    "\n",
    "def cat_log_softmax_split(scores, dim=-1):\n",
    "    cond_scores = scores.split(cond_sizes, dim=dim)\n",
    "    cond_log_softmax = [x.log_softmax(dim=dim) for x in cond_scores]\n",
    "    return torch.cat(cond_log_softmax, dim=dim)\n",
    "\n",
    "theta = torch.randn([b, num_edges]).to(device)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='cat_log_softmax_split(theta, dim=-1)',\n",
    "    globals={\n",
    "        'theta': theta,\n",
    "        'cat_log_softmax_split': cat_log_softmax_split,\n",
    "    })\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9785d50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70c7ac40>\n",
       "cat_log_softmax_split(theta, dim=0)\n",
       "  Median: 1.46 ms\n",
       "  2 measurements, 100 runs per measurement, 1 thread"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try the same thing with dim 0 instead of dim -1.\n",
    "\n",
    "theta = torch.randn([num_edges, b]).to(device)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='cat_log_softmax_split(theta, dim=0)',\n",
    "    globals={\n",
    "        'theta': theta,\n",
    "        'cat_log_softmax_split': cat_log_softmax_split,\n",
    "    })\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d8ccf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 372, 1371])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9d6f7c35b0>\n",
       "torch.log_softmax(theta, dim=-1)\n",
       "  Median: 6.91 ms\n",
       "  3 measurements, 10 runs per measurement, 1 thread"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benchmark a full softmax for each internal node.\n",
    "# (Before considering masked softmax.)\n",
    "\n",
    "theta = torch.randn([b, num_edges]).to(device)\n",
    "theta = theta.unsqueeze(-2).tile([1, num_internal, 1])\n",
    "print(theta.shape)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='torch.log_softmax(theta, dim=-1)',\n",
    "    globals={'theta': theta})\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192ede3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 372, 1371])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70c7a580>\n",
       "torch.log_softmax(theta, dim=-1)\n",
       "  Median: 6.93 ms\n",
       "  3 measurements, 10 runs per measurement, 1 thread"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try unique values rather than tiled.\n",
    "\n",
    "theta = torch.randn([b, num_internal, num_edges]).to(device)\n",
    "print(theta.shape)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='torch.log_softmax(theta, dim=-1)',\n",
    "    globals={'theta': theta})\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ac24b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 372, 26])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9d8d06c970>\n",
       "torch.log_softmax(theta, dim=-1)\n",
       "  Median: 120.35 us\n",
       "  2 measurements, 1000 runs per measurement, 1 thread"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try smaller softmax.\n",
    "\n",
    "theta = torch.randn([b, num_internal, max_children]).to(device)\n",
    "print(theta.shape)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='torch.log_softmax(theta, dim=-1)',\n",
    "    globals={'theta': theta})\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00b45f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70d2c340>\n",
       "torch.log_softmax(split_scores(theta, dim=-1), dim=-1)\n",
       "  222.05 us\n",
       "  1 measurement, 1000 runs , 1 thread"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, there is potential for a speed-up.\n",
    "# Try constructing array for vectorized log-softmax.\n",
    "\n",
    "row_index = np.concatenate([np.full(n, i) for i, n in enumerate(cond_sizes)])\n",
    "col_index = np.concatenate([np.arange(n) for n in cond_sizes])\n",
    "flat_index = row_index * max_children + col_index\n",
    "flat_index = torch.from_numpy(flat_index).to(device)\n",
    "\n",
    "def split_scores(theta, dim=-1):\n",
    "    assert dim == -1\n",
    "    input_shape = list(theta.shape)\n",
    "    flat_shape = [*input_shape[:-1], num_internal * max_children]\n",
    "    flat = torch.full(flat_shape, -torch.inf, device=theta.device)\n",
    "    flat.index_copy_(dim, flat_index, theta)\n",
    "    split_shape = [*input_shape[:-1], num_internal, max_children]\n",
    "    return flat.reshape(split_shape)\n",
    "\n",
    "theta = torch.randn([b, num_edges], device=device)\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='torch.log_softmax(split_scores(theta, dim=-1), dim=-1)',\n",
    "    globals={\n",
    "        'theta': theta,\n",
    "        'split_scores': split_scores,\n",
    "    })\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3535cf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.benchmark.utils.common.Measurement object at 0x7f9c70c7aa90>\n",
       "hier_log_softmax(theta, dim=-1)\n",
       "  278.44 us\n",
       "  1 measurement, 1000 runs , 1 thread"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put it together.\n",
    "# Split scores, take log-softmax and re-assemble.\n",
    "\n",
    "def hier_log_softmax(theta, dim=-1):\n",
    "    assert dim == -1\n",
    "    input_shape = list(theta.shape)\n",
    "    flat_shape = [*input_shape[:-1], num_internal * max_children]\n",
    "\n",
    "    child_theta = split_scores(theta, dim=-1)\n",
    "    child_logp = torch.log_softmax(child_theta, dim=-1)\n",
    "    child_logp = child_logp.reshape(flat_shape)\n",
    "    logp = child_logp.index_select(-1, flat_index)\n",
    "    # Add a zero for the root node.\n",
    "    zero = torch.zeros([*input_shape[:-1], 1], device=device)\n",
    "    return torch.cat([zero, logp], dim=-1)\n",
    "\n",
    "\n",
    "timer = benchmark.Timer(\n",
    "    stmt='hier_log_softmax(theta, dim=-1)',\n",
    "    globals={\n",
    "        'theta': theta,\n",
    "        'hier_log_softmax': hier_log_softmax,\n",
    "    })\n",
    "timer.blocked_autorange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4b638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
