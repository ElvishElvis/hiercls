{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b16a5cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import json\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import ml_collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import hier\n",
    "import hier_torch\n",
    "import infer\n",
    "import main\n",
    "import metrics\n",
    "import progmet\n",
    "import tree_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2602504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trial = collections.namedtuple('Trial', ['root', 'config_file', 'model_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478a1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Flat softmax with label smoothing.\n",
    "# PLOT_DIR = 'output/plots/sweep_label_smoothing'\n",
    "# EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments/2022-03-31-inat21mini')\n",
    "# EXPERIMENT_PATTERNS = [\n",
    "#     'flat_softmax-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     'flat_softmax-ls-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "# ]\n",
    "# config_to_hparams = lambda c: (c.train.label_smoothing,)\n",
    "# predicate = lambda ls: ls < 0.6\n",
    "\n",
    "\n",
    "# # Multilabel focal loss.\n",
    "# PLOT_DIR = 'output/plots/sweep_multilabel_focal'\n",
    "# EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments')\n",
    "# EXPERIMENT_PATTERNS = [\n",
    "#     '2022-03-31-inat21mini-dgx/multilabel_focal-*-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     '2022-03-31-inat21mini/multilabel_focal-0.*-0-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     '2022-03-31-inat21mini/multilabel_focal-none-*-0-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "# ]\n",
    "# config_to_hparams = lambda c: (c.train.focal_gamma, c.train.focal_alpha)\n",
    "# predicate = lambda gamma, alpha: alpha >= 0.4 and gamma > 0\n",
    "\n",
    "\n",
    "# # Multilabel focal loss, including `loss_weighting`.\n",
    "# PLOT_DIR = 'output/plots/sweep_multilabel_focal'\n",
    "# EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments')\n",
    "# EXPERIMENT_PATTERNS = [\n",
    "#     '2022-03-31-inat21mini-dgx/multilabel_focal-*-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     '2022-03-31-inat21mini/multilabel_focal-inv_sqrt-*-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "# ]\n",
    "# config_to_hparams = lambda c: (c.train.focal_gamma, c.train.focal_alpha, c.train.loss_weighting)\n",
    "# predicate = lambda gamma, alpha, loss_weighting: True\n",
    "\n",
    "\n",
    "# # Bertinetto HXE loss.\n",
    "# PLOT_DIR = 'output/plots/sweep_hxe'\n",
    "# EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments')\n",
    "# EXPERIMENT_PATTERNS = [\n",
    "#     '2022-03-31-inat21mini/flat_softmax-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     # '2022-03-31-inat21mini/flat_bertinetto-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "#     '2022-05-12-hxe-sweep/flat_bertinetto-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "# ]\n",
    "# config_to_hparams = lambda c: (c.train.hxe_alpha,)\n",
    "# predicate = lambda alpha: True\n",
    "\n",
    "\n",
    "# Deep RTC (cut prob).\n",
    "PLOT_DIR = 'output/plots/sweep_deep_rtc'\n",
    "EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments/2022-03-31-inat21mini')\n",
    "EXPERIMENT_PATTERNS = [\n",
    "    'share_random_cut-*-lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "]\n",
    "config_to_hparams = lambda c: (c.train.random_cut_prob,)\n",
    "predicate = lambda alpha: True\n",
    "\n",
    "\n",
    "# # Margin (scale).\n",
    "# PLOT_DIR = 'output/plots/sweep_soft_margin'\n",
    "# EXP_DIR = pathlib.Path('/mnt/ssd1/projects/2022-01-hierarchical/experiments/2022-03-31-inat21mini')\n",
    "# EXPERIMENT_PATTERNS = [\n",
    "#     'soft_margin-incorrect-*lr-0.01-b-64-wd-0.0003-ep-20',\n",
    "# ]\n",
    "# config_to_hparams = lambda c: (c.train.margin_tau,)\n",
    "# predicate = lambda tau: True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8692371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config):\n",
    "    if not hasattr(config.train, 'loss_weighting'):\n",
    "        setattr(config.train, 'loss_weighting', 'none')\n",
    "    if not hasattr(config.train, 'margin_tau'):\n",
    "        setattr(config.train, 'margin_tau', 1.0)\n",
    "    return config  # For convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "017be255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['share_random_cut-0-lr-0.01-b-64-wd-0.0003-ep-20',\n",
       " 'share_random_cut-0.1-lr-0.01-b-64-wd-0.0003-ep-20']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments = {\n",
    "    path.name: Trial(\n",
    "        root=path,\n",
    "        config_file=path / 'config.json',\n",
    "        model_file=path / 'checkpoints/epoch-0020.pth')\n",
    "    for path in sorted(itertools.chain.from_iterable(\n",
    "        pathlib.Path(EXP_DIR).glob(pattern) for pattern in EXPERIMENT_PATTERNS))\n",
    "    if (path / 'checkpoints/epoch-0020.pth').exists()\n",
    "}\n",
    "list(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdca2bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'share_random_cut-0-lr-0.01-b-64-wd-0.0003-ep-20': (0.0,),\n",
       " 'share_random_cut-0.1-lr-0.01-b-64-wd-0.0003-ep-20': (0.1,)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get params from JSON file not filename (less prone to human error).\n",
    "\n",
    "configs = {}\n",
    "for k, experiment in experiments.items():\n",
    "    with open(experiment.config_file) as f:\n",
    "        configs[k] = update_config(ml_collections.ConfigDict(json.load(f)))\n",
    "\n",
    "experiment_hparams = {k: config_to_hparams(c) for k, c in configs.items()}\n",
    "experiment_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a0f5d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'share_random_cut-0-lr-0.01-b-64-wd-0.0003-ep-20': (0.0,),\n",
       " 'share_random_cut-0.1-lr-0.01-b-64-wd-0.0003-ep-20': (0.1,)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter using predicate.\n",
    "\n",
    "experiment_hparams = {k: hparams for k, hparams in experiment_hparams.items() if predicate(*hparams)}\n",
    "experiments = {k: experiments[k] for k in experiment_hparams}\n",
    "experiment_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52b5fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0.0,): 'share_random_cut-0-lr-0.01-b-64-wd-0.0003-ep-20',\n",
       " (0.1,): 'share_random_cut-0.1-lr-0.01-b-64-wd-0.0003-ep-20'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Arrange by key, ensure unique.\n",
    "\n",
    "hparams_to_key = dict(sorted((v, k) for k, v in experiment_hparams.items()))\n",
    "assert len(hparams_to_key) == len(experiment_hparams), 'hparams not unique'\n",
    "\n",
    "colors = dict(zip(\n",
    "    hparams_to_key,\n",
    "    map(matplotlib.cm.get_cmap('tab10'), itertools.count())))\n",
    "\n",
    "hparams_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbf1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06047af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configs.inaturalist2021mini\n",
    "\n",
    "base_config = configs.inaturalist2021mini.get_config()\n",
    "base_config.dataset_root = '/home/jack/data/manual/inaturalist2021/'\n",
    "\n",
    "_, eval_dataset, tree, _, _, eval_label_map = main.make_datasets(base_config)\n",
    "\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    dataset=eval_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "562d30aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_leaf = tree.leaf_mask()\n",
    "specificity = -tree.num_leaf_descendants()\n",
    "not_trivial = (tree.num_children() != 1)\n",
    "subtract_children_fn = hier_torch.SubtractChildren(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40150867",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_fns = {\n",
    "    'leaf': lambda p: infer.argmax_where(p, is_leaf),\n",
    "    'majority': lambda p: infer.argmax_with_confidence(specificity, p, 0.5, not_trivial),\n",
    "    # 'exclusive': lambda p: np.argmax(subtract_children_fn(torch.from_numpy(p)).numpy(), axis=-1),\n",
    "}\n",
    "\n",
    "markers = {\n",
    "    'leaf': 'o',\n",
    "    'majority': '^',\n",
    "    # 'exclusive': 'd',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f9f0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_metric = metrics.UniformLeafInfoMetric(tree)\n",
    "depth_metric = metrics.DepthMetric(tree)\n",
    "\n",
    "metric_fns = {\n",
    "    'exact': lambda gt, pr: pr == gt,\n",
    "    'correct': metrics.IsCorrect(tree),\n",
    "    'info_excess': info_metric.excess,\n",
    "    'info_deficient': info_metric.deficient,\n",
    "    'info_dist': info_metric.dist,\n",
    "    'info_recall': info_metric.recall,\n",
    "    'info_precision': info_metric.precision,\n",
    "    'depth_excess': depth_metric.excess,\n",
    "    'depth_deficient': depth_metric.deficient,\n",
    "    'depth_dist': depth_metric.dist,\n",
    "    'depth_recall': depth_metric.recall,\n",
    "    'depth_precision': depth_metric.precision,\n",
    "}\n",
    "\n",
    "metric_titles = {\n",
    "    'exact': 'Exact',\n",
    "    'correct': 'Correct',\n",
    "    'info_recall': 'Information Recall',\n",
    "    'info_precision': 'Information Precision',\n",
    "    'depth_recall': 'Depth Recall',\n",
    "    'depth_precision': 'Depth Precision',\n",
    "    'info_lca': 'LCA Information',\n",
    "    'depth_lca': 'LCA Depth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321bfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(net, pred_fn, min_threshold, limit=None):\n",
    "    # Per-example predictions.\n",
    "\n",
    "    outputs = {\n",
    "        'gt': [],  # Node in hierarchy.\n",
    "        'pred': {method: [] for method in infer_fns},\n",
    "    }\n",
    "    # Sequence-per-example predictions. Cannot be concatenated due to ragged shape.\n",
    "    seq_outputs = {\n",
    "        'pred': [],\n",
    "        'prob': [],\n",
    "    }\n",
    "\n",
    "    net.eval()\n",
    "    with torch.inference_mode():\n",
    "        meter = progmet.ProgressMeter('apply', interval_time=5)\n",
    "        for minibatch in itertools.islice(meter(eval_loader), limit):\n",
    "            inputs, gt_labels = minibatch\n",
    "            theta = net(inputs.to(device))\n",
    "            prob = pred_fn(theta).cpu().numpy()\n",
    "            pred = {}\n",
    "            for name, infer_fn in infer_fns.items():\n",
    "                pred[name] = infer_fn(prob)\n",
    "            gt_node = eval_label_map.to_node[gt_labels]\n",
    "            pred_seqs = [\n",
    "                infer.pareto_optimal_predictions(specificity, p, min_threshold, not_trivial)\n",
    "                for p in prob\n",
    "            ]\n",
    "            prob_seqs = [prob[i, pred_i] for i, pred_i in enumerate(pred_seqs)]\n",
    "            # Caution: Predictions are *not* truncated.\n",
    "\n",
    "            outputs['gt'].append(gt_node)\n",
    "            for method in infer_fns:\n",
    "                outputs['pred'][method].append(pred[method])\n",
    "            seq_outputs['pred'].extend(pred_seqs)\n",
    "            seq_outputs['prob'].extend(prob_seqs)\n",
    "\n",
    "    # Concatenate results from minibatches.\n",
    "    leaf_predicate = lambda x: not isinstance(x, dict)  # Treat lists as values, not containers.\n",
    "    outputs = tree_util.tree_map(np.concatenate, outputs, is_leaf=leaf_predicate)\n",
    "\n",
    "    return outputs, seq_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6303cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_predictions(outputs, seq_outputs):\n",
    "    gt = outputs['gt']\n",
    "    pred = outputs['pred']\n",
    "    pred_seq = seq_outputs['pred']\n",
    "    prob_seq = seq_outputs['prob']\n",
    "\n",
    "    # Evaluate predictions for each method.\n",
    "    pred = {\n",
    "        method: hier.truncate_at_lca(tree, gt, pr)\n",
    "        for method, pr in pred.items()\n",
    "    }\n",
    "    pred_metrics = {\n",
    "        method: {field: np.mean(metric_fn(gt, pr))\n",
    "                 for field, metric_fn in metric_fns.items()}\n",
    "        for method, pr in pred.items()\n",
    "    }\n",
    "\n",
    "    # Evaluate predictions in Pareto sequence.\n",
    "    find_lca = hier.FindLCA(tree)\n",
    "    specificity_seq = [specificity[pr_i] for pr_i in pred_seq]\n",
    "    pred_seq = [hier.truncate_given_lca(gt_i, pr_i, find_lca(gt_i, pr_i)) for gt_i, pr_i in zip(gt, pred_seq)]\n",
    "    metric_values_seq = {\n",
    "        field: [metric_fn(gt_i, pr_i) for gt_i, pr_i in zip(gt, pred_seq)]\n",
    "        for field, metric_fn in metric_fns.items()\n",
    "    }\n",
    "    pareto_scores, pareto_totals = metrics.operating_curve(prob_seq, metric_values_seq)\n",
    "    pareto_means = {k: v / len(gt) for k, v in pareto_totals.items()}\n",
    "\n",
    "    return pred_metrics, pareto_scores, pareto_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5bff16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_threshold(scores, metric, x):\n",
    "    return metric[np.searchsorted(-scores, -x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36931a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results if not defined.\n",
    "try:\n",
    "    results\n",
    "except NameError:\n",
    "    results = {}  # Not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951431b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "apply:   2% (25/1563); T=0.204 f=4.90; mean T=0.204 f=4.90; elapsed 0:00:05; remaining 0:05:14 of 0:05:19\n",
      "apply:   3% (52/1563); T=0.191 f=5.22; mean T=0.198 f=5.06; elapsed 0:00:10; remaining 0:04:59 of 0:05:09\n",
      "apply:   5% (79/1563); T=0.189 f=5.30; mean T=0.195 f=5.14; elapsed 0:00:15; remaining 0:04:49 of 0:05:04\n",
      "apply:   7% (106/1563); T=0.188 f=5.32; mean T=0.193 f=5.18; elapsed 0:00:20; remaining 0:04:41 of 0:05:01\n",
      "apply:   8% (132/1563); T=0.197 f=5.08; mean T=0.194 f=5.16; elapsed 0:00:26; remaining 0:04:37 of 0:05:03\n",
      "apply:  10% (159/1563); T=0.189 f=5.28; mean T=0.193 f=5.18; elapsed 0:00:31; remaining 0:04:31 of 0:05:02\n",
      "apply:  12% (185/1563); T=0.194 f=5.16; mean T=0.193 f=5.18; elapsed 0:00:36; remaining 0:04:26 of 0:05:02\n",
      "apply:  13% (211/1563); T=0.194 f=5.17; mean T=0.193 f=5.18; elapsed 0:00:41; remaining 0:04:21 of 0:05:02\n",
      "apply:  15% (238/1563); T=0.187 f=5.35; mean T=0.192 f=5.20; elapsed 0:00:46; remaining 0:04:15 of 0:05:01\n",
      "apply:  17% (266/1563); T=0.180 f=5.57; mean T=0.191 f=5.23; elapsed 0:00:51; remaining 0:04:08 of 0:04:59\n",
      "apply:  19% (293/1563); T=0.187 f=5.34; mean T=0.191 f=5.24; elapsed 0:00:56; remaining 0:04:02 of 0:04:58\n",
      "apply:  20% (320/1563); T=0.189 f=5.30; mean T=0.191 f=5.25; elapsed 0:01:01; remaining 0:03:57 of 0:04:58\n",
      "apply:  22% (347/1563); T=0.189 f=5.28; mean T=0.190 f=5.25; elapsed 0:01:06; remaining 0:03:52 of 0:04:58\n",
      "apply:  24% (375/1563); T=0.180 f=5.55; mean T=0.190 f=5.27; elapsed 0:01:11; remaining 0:03:45 of 0:04:56\n",
      "apply:  26% (403/1563); T=0.182 f=5.50; mean T=0.189 f=5.29; elapsed 0:01:16; remaining 0:03:39 of 0:04:56\n",
      "apply:  28% (431/1563); T=0.184 f=5.45; mean T=0.189 f=5.30; elapsed 0:01:21; remaining 0:03:34 of 0:04:55\n",
      "apply:  29% (458/1563); T=0.189 f=5.29; mean T=0.189 f=5.30; elapsed 0:01:26; remaining 0:03:29 of 0:04:55\n",
      "apply:  31% (486/1563); T=0.182 f=5.50; mean T=0.188 f=5.31; elapsed 0:01:32; remaining 0:03:23 of 0:04:54\n",
      "apply:  33% (514/1563); T=0.181 f=5.52; mean T=0.188 f=5.32; elapsed 0:01:37; remaining 0:03:17 of 0:04:54\n",
      "apply:  35% (541/1563); T=0.190 f=5.28; mean T=0.188 f=5.32; elapsed 0:01:42; remaining 0:03:12 of 0:04:54\n",
      "apply:  36% (568/1563); T=0.190 f=5.26; mean T=0.188 f=5.31; elapsed 0:01:47; remaining 0:03:07 of 0:04:54\n",
      "apply:  38% (596/1563); T=0.183 f=5.47; mean T=0.188 f=5.32; elapsed 0:01:52; remaining 0:03:02 of 0:04:54\n",
      "apply:  40% (623/1563); T=0.187 f=5.35; mean T=0.188 f=5.32; elapsed 0:01:57; remaining 0:02:57 of 0:04:54\n",
      "apply:  42% (650/1563); T=0.187 f=5.36; mean T=0.188 f=5.32; elapsed 0:02:02; remaining 0:02:51 of 0:04:54\n",
      "apply:  43% (677/1563); T=0.186 f=5.39; mean T=0.188 f=5.33; elapsed 0:02:07; remaining 0:02:46 of 0:04:53\n",
      "apply:  45% (704/1563); T=0.189 f=5.30; mean T=0.188 f=5.33; elapsed 0:02:12; remaining 0:02:41 of 0:04:53\n",
      "apply:  47% (731/1563); T=0.187 f=5.36; mean T=0.188 f=5.33; elapsed 0:02:17; remaining 0:02:36 of 0:04:53\n",
      "apply:  49% (759/1563); T=0.184 f=5.44; mean T=0.188 f=5.33; elapsed 0:02:22; remaining 0:02:31 of 0:04:53\n",
      "apply:  50% (786/1563); T=0.189 f=5.29; mean T=0.188 f=5.33; elapsed 0:02:27; remaining 0:02:26 of 0:04:53\n",
      "apply:  52% (814/1563); T=0.185 f=5.41; mean T=0.188 f=5.33; elapsed 0:02:33; remaining 0:02:20 of 0:04:53\n",
      "apply:  54% (842/1563); T=0.184 f=5.43; mean T=0.187 f=5.34; elapsed 0:02:38; remaining 0:02:15 of 0:04:53\n",
      "apply:  56% (869/1563); T=0.189 f=5.28; mean T=0.187 f=5.33; elapsed 0:02:43; remaining 0:02:10 of 0:04:53\n",
      "apply:  57% (896/1563); T=0.189 f=5.30; mean T=0.188 f=5.33; elapsed 0:02:48; remaining 0:02:05 of 0:04:53\n",
      "apply:  59% (924/1563); T=0.181 f=5.54; mean T=0.187 f=5.34; elapsed 0:02:53; remaining 0:02:00 of 0:04:53\n",
      "apply:  61% (950/1563); T=0.196 f=5.11; mean T=0.188 f=5.33; elapsed 0:02:58; remaining 0:01:55 of 0:04:53\n",
      "apply:  63% (978/1563); T=0.183 f=5.47; mean T=0.187 f=5.34; elapsed 0:03:03; remaining 0:01:50 of 0:04:53\n",
      "apply:  64% (1006/1563); T=0.180 f=5.57; mean T=0.187 f=5.34; elapsed 0:03:08; remaining 0:01:44 of 0:04:53\n",
      "apply:  66% (1035/1563); T=0.177 f=5.64; mean T=0.187 f=5.35; elapsed 0:03:13; remaining 0:01:39 of 0:04:52\n",
      "apply:  68% (1063/1563); T=0.179 f=5.59; mean T=0.187 f=5.36; elapsed 0:03:18; remaining 0:01:33 of 0:04:52\n",
      "apply:  70% (1091/1563); T=0.179 f=5.59; mean T=0.186 f=5.36; elapsed 0:03:23; remaining 0:01:28 of 0:04:51\n",
      "apply:  72% (1119/1563); T=0.180 f=5.54; mean T=0.186 f=5.37; elapsed 0:03:29; remaining 0:01:23 of 0:04:51\n",
      "apply:  73% (1148/1563); T=0.175 f=5.72; mean T=0.186 f=5.37; elapsed 0:03:34; remaining 0:01:17 of 0:04:51\n",
      "apply:  75% (1177/1563); T=0.178 f=5.61; mean T=0.186 f=5.38; elapsed 0:03:39; remaining 0:01:12 of 0:04:50\n",
      "apply:  77% (1205/1563); T=0.180 f=5.55; mean T=0.186 f=5.38; elapsed 0:03:44; remaining 0:01:06 of 0:04:50\n",
      "apply:  79% (1233/1563); T=0.183 f=5.47; mean T=0.186 f=5.39; elapsed 0:03:49; remaining 0:01:01 of 0:04:50\n",
      "apply:  81% (1260/1563); T=0.187 f=5.36; mean T=0.186 f=5.39; elapsed 0:03:54; remaining 0:00:56 of 0:04:50\n",
      "apply:  82% (1289/1563); T=0.177 f=5.66; mean T=0.185 f=5.39; elapsed 0:03:59; remaining 0:00:51 of 0:04:50\n",
      "apply:  84% (1318/1563); T=0.174 f=5.74; mean T=0.185 f=5.40; elapsed 0:04:04; remaining 0:00:45 of 0:04:50\n",
      "apply:  86% (1347/1563); T=0.177 f=5.64; mean T=0.185 f=5.40; elapsed 0:04:09; remaining 0:00:40 of 0:04:49\n",
      "apply:  88% (1377/1563); T=0.172 f=5.83; mean T=0.185 f=5.41; elapsed 0:04:14; remaining 0:00:34 of 0:04:49\n",
      "apply:  90% (1405/1563); T=0.181 f=5.52; mean T=0.185 f=5.41; elapsed 0:04:20; remaining 0:00:29 of 0:04:49\n",
      "apply:  92% (1433/1563); T=0.179 f=5.59; mean T=0.185 f=5.42; elapsed 0:04:25; remaining 0:00:24 of 0:04:49\n"
     ]
    }
   ],
   "source": [
    "MIN_THRESHOLD = None  # Values less than 0.5 may increase runtime significantly.\n",
    "LIMIT = None\n",
    "\n",
    "score_grid = np.flip(np.linspace(0, 1, 10001))\n",
    "\n",
    "for name, experiment in experiments.items():\n",
    "    if name in results:\n",
    "        print('cached:', name)\n",
    "        continue\n",
    "\n",
    "    # Load model.\n",
    "    with open(experiment.config_file, 'r') as f:\n",
    "        config = update_config(ml_collections.ConfigDict(json.load(f)))\n",
    "    num_outputs = main.get_num_outputs(config.predict, tree)\n",
    "    net = main.make_model(config.model, num_outputs)\n",
    "    missing_keys, unexpected_keys = net.load_state_dict(torch.load(experiment.model_file), strict=True)\n",
    "    assert not missing_keys\n",
    "    assert not unexpected_keys\n",
    "\n",
    "    net.to(device)\n",
    "    _, pred_fn = main.make_loss(config, tree, device)\n",
    "    outputs, seq_outputs = apply_model(net, pred_fn, min_threshold=MIN_THRESHOLD, limit=LIMIT)\n",
    "    pred_metrics, pareto_scores, pareto_metrics = assess_predictions(outputs, seq_outputs)\n",
    "    trial_results = {\n",
    "        'pred_metrics': pred_metrics,\n",
    "        'pareto_scores': pareto_scores,\n",
    "        'pareto_metrics': pareto_metrics,\n",
    "    }\n",
    "\n",
    "    # Re-sample the Pareto front; also keeps the memory footprint down.\n",
    "    trial_results.update({\n",
    "        'pareto_scores': score_grid[1:],\n",
    "        'pareto_metrics': {\n",
    "            field: resample_threshold(\n",
    "                trial_results['pareto_scores'],\n",
    "                trial_results['pareto_metrics'][field],\n",
    "                score_grid)\n",
    "            for field in trial_results['pareto_metrics']\n",
    "        },\n",
    "    })\n",
    "    results[name] = trial_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf94a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTEGRALS = {\n",
    "    'AC(depth)': ('depth_recall', 'correct'),\n",
    "    'AC(info)': ('info_recall', 'correct'),\n",
    "    'AP(depth)': ('depth_recall', 'depth_precision'),\n",
    "    'AP(info)': ('info_recall', 'info_precision'),\n",
    "    'AC(exact)': ('exact', 'correct'),\n",
    "}\n",
    "\n",
    "auc = {\n",
    "    integral_key: {\n",
    "        name: metrics.pareto_integrate(\n",
    "            results[name]['pareto_metrics'][x],\n",
    "            results[name]['pareto_metrics'][y])\n",
    "        for name in experiments if name in results\n",
    "    } for integral_key, (x, y) in INTEGRALS.items()\n",
    "}\n",
    "\n",
    "auc = pd.DataFrame(auc)\n",
    "auc = auc.set_index(auc.index.map(experiment_hparams)).sort_index()\n",
    "auc.style.format('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58049feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc.sort_values('AP(info)', ascending=False).style.format('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20042c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERCEPTS = [\n",
    "    'depth_recall',\n",
    "    'info_recall',\n",
    "    'exact',\n",
    "]\n",
    "\n",
    "CORRECT = [95, 90]\n",
    "\n",
    "recalls = {\n",
    "    (c, y): {\n",
    "        name: metrics.pareto_intercept(\n",
    "            results[name]['pareto_metrics']['correct'],\n",
    "            results[name]['pareto_metrics'][y],\n",
    "            c / 100)\n",
    "        for name in results\n",
    "    } for c in CORRECT for y in INTERCEPTS\n",
    "}\n",
    "\n",
    "recalls = pd.DataFrame(recalls)\n",
    "recalls = recalls.set_index(recalls.index.map(experiment_hparams)).sort_index()\n",
    "recalls.style.format('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8190c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls.sort_values((90, 'info_recall'), ascending=False).style.format('{:.1%}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19078a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(x, y, tickres=None, is_pr=True, save=False):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    for hparams, name in hparams_to_key.items():\n",
    "        pred_metrics = results[name]['pred_metrics']\n",
    "        pareto_scores = results[name]['pareto_scores']\n",
    "        pareto_metrics = results[name]['pareto_metrics']\n",
    "        ge = np.concatenate(([True], pareto_scores >= 0.5))\n",
    "        le = np.concatenate(([False], pareto_scores <= 0.5))\n",
    "        plt.plot(pareto_metrics[x][ge], pareto_metrics[y][ge],\n",
    "                 color=colors[hparams], label=', '.join(map(str, hparams)))\n",
    "        plt.plot(pareto_metrics[x][le], pareto_metrics[y][le],\n",
    "                 color=colors[hparams], linestyle='--')\n",
    "        for method in ['leaf', 'majority']:  # pred_metrics.items():\n",
    "            plt.plot(pred_metrics[method][x], pred_metrics[method][y],\n",
    "                     color=colors[hparams], marker=markers[method],\n",
    "                     markerfacecolor='none')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    if is_pr:\n",
    "        plt.xlim(left=0)\n",
    "        plt.ylim(top=1)\n",
    "        # plt.ylim(np.clip(plt.ylim(), 0, 1))\n",
    "        # plt.xlim(np.clip(plt.xlim(), 0, 1))\n",
    "    if tickres:\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(tickres))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(tickres))\n",
    "    # plt.axis('equal')\n",
    "    # plt.gca().set_aspect(1)\n",
    "    plt.grid()\n",
    "    plt.xlabel(metric_titles.get(x, x))\n",
    "    plt.ylabel(metric_titles.get(y, y))\n",
    "    plt.legend()\n",
    "\n",
    "    if save:\n",
    "        pathlib.Path(PLOT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(pathlib.Path(PLOT_DIR) / f'{x}-{y}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('exact', 'correct', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('info_recall', 'correct', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('info_recall', 'info_precision', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de93848",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('depth_recall', 'correct', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c187ce11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics('depth_recall', 'depth_precision', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defbd73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
